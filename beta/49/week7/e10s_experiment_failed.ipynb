{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# e10s-addons-beta49-week7: Main analysis\n",
    "\n",
    "(This covers data from 2016-09-14 to 2016-09-21 on Beta 49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse whitelist (/home/hadoop/anaconda2/lib/python2.7/site-packages/moztelemetry/histogram-whitelists.json). Assuming all histograms are acceptable.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import ujson as json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import plotly.plotly as py\n",
    "import IPython\n",
    "import pyspark.sql.functions as fun\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from __future__ import division\n",
    "from moztelemetry.spark import get_pings, get_one_ping_per_client, get_pings_properties\n",
    "from montecarlino import grouped_permutation_test\n",
    "\n",
    "%pylab inline\n",
    "IPython.core.pylabtools.figsize(16, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'2.0.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chi2_distance(xs, ys, eps = 1e-10, normalize = True):\n",
    "    \"\"\" The comparison metric for histograms. \"\"\"\n",
    "    histA = xs.sum(axis=0)\n",
    "    histB = ys.sum(axis=0)\n",
    "    \n",
    "    if normalize:\n",
    "        histA = histA/histA.sum()\n",
    "        histB = histB/histB.sum()\n",
    "    \n",
    "    d = 0.5 * np.sum([((a - b) ** 2) / (a + b + eps)\n",
    "        for (a, b) in zip(histA, histB)])\n",
    "\n",
    "    return d\n",
    "\n",
    "def median_diff(xs, ys):\n",
    "    return np.median(xs) - np.median(ys)\n",
    "\n",
    "def make_group_histogram(group_data):\n",
    "    \"\"\" Combine separate client histograms into a single group histogram, normalizing bin counts\n",
    "        to relative frequencies.       \n",
    "    \"\"\"\n",
    "    ## Check for histograms with 0 counts.\n",
    "    client_totals = group_data.map(lambda x: x.sum())\n",
    "    group_data = group_data[client_totals > 0]\n",
    "    ## Convert frequency counts to relative frequency for each client histogram.\n",
    "    group_data = group_data.map(lambda x: x/x.sum())\n",
    "    ## Merge the group's client histograms by adding up the frequencies over all clients\n",
    "    ## in the group, separately for each bin.\n",
    "    group_data = group_data.sum()\n",
    "    ## Convert the merged bin frequencies to relative percentages.\n",
    "    group_data = 100 * group_data / group_data.sum()\n",
    "    return group_data\n",
    "    \n",
    "\n",
    "def compare_histogram(histogram, e10s_addons, none10s_addons, e10s_std=None, none10s_std=None,\n",
    "                      include_diff=True, include_diff_in_diff=True, did_separate_plot=True):\n",
    "    \"\"\" Compare an e10s histogram to a non-e10s one, and graph the results.\n",
    "        \n",
    "        Plots the two histograms overlaid on the same graph, and prints a p-value\n",
    "        for testing whether they are different. If 'include_diff' is True, also\n",
    "        draw a plot of the frequency differences for each bin.\n",
    "        \n",
    "        If 'include_diff_in_diff' is True and data is supplied, include a plot of\n",
    "        differences between addon cohort differences and non-addon cohort differences.\n",
    "    \"\"\"\n",
    "    eTotal = make_group_histogram(e10s_addons)\n",
    "    nTotal = make_group_histogram(none10s_addons)\n",
    "    \n",
    "    if include_diff:\n",
    "        if include_diff_in_diff and did_separate_plot:\n",
    "            fig, (ax, diff_ax, diff_diff_ax) = plt.subplots(3, sharex=True, figsize=(16,10), \n",
    "                                                            gridspec_kw={\"height_ratios\": [2,2,1]})\n",
    "        else:\n",
    "            fig, (ax, diff_ax) = plt.subplots(2, sharex=True)\n",
    "    else:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "    fig.subplots_adjust(hspace=0.3)\n",
    "    \n",
    "    ax2 = ax.twinx()\n",
    "    width = 0.4\n",
    "    ylim = max(eTotal.max(), nTotal.max())\n",
    "        \n",
    "    eTotal.plot(kind=\"bar\", alpha=0.5, color=\"green\", label=\"e10s\", ax=ax, width=width,\n",
    "                position=0, ylim=(0, ylim + 1))\n",
    "    nTotal.plot(kind=\"bar\", alpha=0.5, color=\"blue\", label=\"non-e10s\", ax=ax2, width=width,\n",
    "                position=1, grid=False, ylim=ax.get_ylim())\n",
    "    \n",
    "    ## Combine legend info from both Axes.\n",
    "    ax_h, ax_l = ax.get_legend_handles_labels()\n",
    "    ax2_h, ax2_l = ax2.get_legend_handles_labels()\n",
    "    ax.legend(ax_h + ax2_h, ax_l + ax2_l, loc = 0)\n",
    " \n",
    "    plt.title(histogram)\n",
    "    ax.set_ylabel(\"Frequency %\")\n",
    "    \n",
    "    if include_diff:\n",
    "        ## Add a second barplot of the difference in frequency for each bucket.\n",
    "        #diff_ax = fig.add_subplot(2, 1, 2)\n",
    "        enDiff = eTotal - nTotal\n",
    "        \n",
    "        has_diff_in_diff_data = (e10s_std is not None and len(e10s_std) > 0 and\n",
    "                                 none10s_std is not None and len(none10s_std) > 0)\n",
    "        if include_diff_in_diff and has_diff_in_diff_data:\n",
    "            ## Add bin differences for between e10s/non-e10s for the no-addons cohorts.\n",
    "            ## The assumption is that the difference between addons cohorts would look the same\n",
    "            ## if there is no additional effect of having addons.\n",
    "            eTotal_std = make_group_histogram(e10s_std)\n",
    "            nTotal_std = make_group_histogram(none10s_std)\n",
    "            enDiff_std = eTotal_std - nTotal_std\n",
    "            ylims = (min(enDiff.min(), enDiff_std.min()) - 0.5, max(enDiff.max(), enDiff_std.max()) + 0.5)\n",
    "            diff_ax2 = diff_ax.twinx()\n",
    "            \n",
    "            enDiff.plot(kind=\"bar\", alpha=0.5, color=\"navy\", label=\"with add-ons\", ax=diff_ax, width=width,\n",
    "                        position=1, ylim=ylims)\n",
    "            enDiff_std.plot(kind=\"bar\", alpha=0.5, color=\"white\", label=\"no add-ons\", ax=diff_ax2, width=width,\n",
    "                        position=0, grid=False, ylim=diff_ax.get_ylim())\n",
    "\n",
    "            ## Combine legend info from both Axes.\n",
    "            diff_ax_h, diff_ax_l = diff_ax.get_legend_handles_labels()\n",
    "            diff_ax2_h, diff_ax2_l = diff_ax2.get_legend_handles_labels()\n",
    "            leg_h = diff_ax_h + diff_ax2_h\n",
    "            leg_l = diff_ax_l + diff_ax2_l\n",
    "            \n",
    "            if did_separate_plot:\n",
    "                enDiffDiff = enDiff - enDiff_std\n",
    "                enDiffDiff.plot(kind=\"bar\", color=\"maroon\", ax=diff_diff_ax, ylim=diff_ax.get_ylim())\n",
    "                diff_diff_ax.set_ylabel(\"Diff in freq %\")\n",
    "                diff_diff_ax.set_title(\"Diff between e10s/non diff with add-ons and e10s/non diff without\" +\n",
    "                                      \" (with add-ons higher when > 0)\")\n",
    "            \n",
    "        else:\n",
    "            if include_diff_in_diff:\n",
    "                ## We wanted to do the additional comparison, but there wasn't enough data.\n",
    "                print(\"\\nNo diff-in-diff comparison: one of the standard cohorts has no non-missing observations.\")\n",
    "            enDiff.plot(kind=\"bar\", alpha=0.5, color=\"navy\", label=\"with add-ons\", ax=diff_ax)\n",
    "            leg_h, leg_l = diff_ax.get_legend_handles_labels()\n",
    "        \n",
    "        plt.title(\"e10s/non-e10s difference (more e10s in bucket when > 0)\")\n",
    "        diff_ax.set_ylabel(\"Diff in frequency %\")\n",
    "        diff_ax.legend(leg_h, leg_l, loc = 0)\n",
    "    \n",
    "    \n",
    "    # Only display at most 100 tick labels on the x axis.\n",
    "    xticklabs = plt.gca().get_xticklabels()\n",
    "    max_x_ticks = 100\n",
    "    if len(xticklabs) > max_x_ticks:\n",
    "        step_size = math.ceil(float(len(xticklabs)) / max_x_ticks)\n",
    "        for i, tl in enumerate(xticklabs):\n",
    "            if i % step_size != 0:\n",
    "                tl.set_visible(False)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    ## Compute a p-value for the chi-square distance between the groups' combined histograms.\n",
    "    pvalue = grouped_permutation_test(chi2_distance, [e10s_addons, none10s_addons], num_samples=100)\n",
    "    print(\"The probability that the distributions for {} (with add-ons) are differing by chance is {:.3f}.\"\\\n",
    "          .format(histogram, pvalue))\n",
    "\n",
    "def normalize_uptime_hour(frame):\n",
    "    \"\"\" Convert metrics to rates per hour of uptime. \"\"\"\n",
    "    frame = frame[frame[\"payload/simpleMeasurements/totalTime\"] > 60]\n",
    "    frame = 60 * 60 * frame.apply(lambda x: x / frame[\"payload/simpleMeasurements/totalTime\"]) # Metric per hour\n",
    "    frame.drop('payload/simpleMeasurements/totalTime', axis=1, inplace=True)\n",
    "    return frame\n",
    "    \n",
    "def compare_e10s_count_histograms(pings, cohort_sizes = {}, *histogram_names, **kwargs):\n",
    "    \"\"\" Read multiple count histograms from a collection of pings, and compare e10s/non-e10s for each.\n",
    "    \n",
    "        Treats count histograms as scalars for comparison purposes, without distinguishing between\n",
    "        parent and child processes. Expects a dict containing overall cohort sizes\n",
    "        for computing sample size proportions.\n",
    "    \"\"\"\n",
    "    properties = histogram_names + (\"payload/simpleMeasurements/totalTime\", \"e10s\", \"addons\")\n",
    "    frame = pd.DataFrame(get_pings_properties(pings, properties).collect())\n",
    "\n",
    "    e10s = frame[frame[\"addons\"] & frame[\"e10s\"]]\n",
    "    e10s = normalize_uptime_hour(e10s)\n",
    "    \n",
    "    none10s = frame[frame[\"addons\"] & ~frame[\"e10s\"]]\n",
    "    none10s = normalize_uptime_hour(none10s)\n",
    "    \n",
    "    include_diff_in_diff = kwargs.get(\"include_diff_in_diff\", True)\n",
    "    if include_diff_in_diff:\n",
    "        e10s_std = normalize_uptime_hour(frame[~frame[\"addons\"] & frame[\"e10s\"]])\n",
    "        none10s_std = normalize_uptime_hour(frame[~frame[\"addons\"] & ~frame[\"e10s\"]])        \n",
    "    \n",
    "    for histogram in histogram_names:\n",
    "        if histogram not in none10s.columns:\n",
    "            continue\n",
    "        \n",
    "        ## Remove the property path from the histogram name for display purposes.\n",
    "        hist_name = hist_base_name(histogram)\n",
    "        ## Print a header for the block of graphs, including a link to the histogram definition.\n",
    "        print_with_markdown(\"Comparison for count histogram {} (with add-ons):\".format(link_to_histogram(hist_name)))\n",
    "        \n",
    "        e10s_hist = e10s[histogram].dropna()\n",
    "        non_e10s_hist = none10s[histogram].dropna()\n",
    "        \n",
    "        ## Print some information on sample sizes.\n",
    "        print(\"{} non-e10s profiles have this histogram.\".format(\n",
    "                sample_size_str(len(non_e10s_hist), cohort_sizes.get(\"addons-set2a-control\"))))\n",
    "        print(\"{} e10s profiles have this histogram.\".format(\n",
    "                sample_size_str(len(e10s_hist), cohort_sizes.get(\"addons-set2a-test\"))))\n",
    "        ## If either group has no data, nothing more to do.\n",
    "        if len(non_e10s_hist) == 0 or len(e10s_hist) == 0:\n",
    "            continue\n",
    "        \n",
    "        print(\"\")\n",
    "        compare_scalars(hist_name + \" per hour\", e10s_hist, non_e10s_hist,\n",
    "                        e10s_std[histogram].dropna() if include_diff_in_diff else None,\n",
    "                        none10s_std[histogram].dropna() if include_diff_in_diff else None)\n",
    " \n",
    "def compare_e10s_histograms(pings, cohort_sizes = {}, *histogram_names, **kwargs):\n",
    "    \"\"\" Read multiple histograms from a collection of pings, and compare e10s/non-e10s for each.\n",
    "    \n",
    "        Outputs separate comparisons for parent process, child processes, and merged histograms.\n",
    "        Expects a dict containing overall cohort sizes for computing sample\n",
    "        size proportions.\n",
    "    \"\"\"\n",
    "    ## Load histogram data from the ping set, separating parent & child processes for e10s.\n",
    "    frame = pd.DataFrame(get_pings_properties(pings, histogram_names + (\"e10s\", \"addons\") , with_processes=True)\\\n",
    "        .collect())\n",
    "    ## The addons experiment cohorts.\n",
    "    e10s_addons = frame[frame[\"addons\"] & frame[\"e10s\"]]\n",
    "    none10s_addons = frame[frame[\"addons\"] & ~frame[\"e10s\"]]\n",
    "    ## The standard experiment cohorts.\n",
    "    e10s_std = frame[~frame[\"addons\"] & frame[\"e10s\"]]\n",
    "    none10s_std = frame[~frame[\"addons\"] & ~frame[\"e10s\"]]\n",
    "    \n",
    "    for histogram in histogram_names:\n",
    "        if histogram not in none10s_addons.columns:\n",
    "            continue\n",
    "        \n",
    "        ## Remove the property path from the histogram name for display purposes.\n",
    "        hist_name = hist_base_name(histogram)\n",
    "        ## Print a header for the block of graphs, including a link to the histogram definition.\n",
    "        print_with_markdown(\"Comparison for {} (with add-ons):\".format(link_to_histogram(hist_name)))\n",
    "        \n",
    "        ## Compare the main histogram for non-e10s against each of 3 for e10s.\n",
    "        addons_hist_data = {\n",
    "            \"non_e10s\": none10s_addons[histogram],\n",
    "            \"e10s_merged\": e10s_addons[histogram],\n",
    "            \"e10s_parent\": e10s_addons[histogram + \"_parent\"],\n",
    "            \"e10s_children\": e10s_addons[histogram + \"_children\"]\n",
    "        }\n",
    "        for htype in addons_hist_data:\n",
    "            addons_hist_data[htype] = addons_hist_data[htype].dropna()\n",
    "        \n",
    "        ## Print some information on sample sizes.\n",
    "        sample_sizes = { htype: len(hdata) for htype, hdata in addons_hist_data.iteritems() }\n",
    "        print(\"{} non-e10s profiles have this histogram.\".format(\n",
    "                sample_size_str(sample_sizes[\"non_e10s\"], cohort_sizes.get(\"addons-set2a-control\"))))\n",
    "        print(\"{} e10s profiles have this histogram.\".format(\n",
    "                sample_size_str(sample_sizes[\"e10s_merged\"], cohort_sizes.get(\"addons-set2a-test\"))))\n",
    "        ## If either group has no data, nothing more to do.\n",
    "        if sample_sizes[\"non_e10s\"] == 0 or sample_sizes[\"e10s_merged\"] == 0:\n",
    "            continue\n",
    "        \n",
    "        print(\"{} e10s profiles have the parent histogram.\".format(\n",
    "                sample_size_str(sample_sizes[\"e10s_parent\"], cohort_sizes.get(\"addons-set2a-test\"))))\n",
    "        print(\"{} e10s profiles have the children histogram.\".format(\n",
    "                sample_size_str(sample_sizes[\"e10s_children\"], cohort_sizes.get(\"addons-set2a-test\"))))\n",
    "        \n",
    "        has_parent = sample_sizes[\"e10s_parent\"] > 0\n",
    "        has_children = sample_sizes[\"e10s_children\"] > 0\n",
    "        \n",
    "        non_e10s_std_hist = none10s_std[histogram].dropna()\n",
    "        \n",
    "        ## Compare merged histograms, unless e10s group has either no parents or no children.\n",
    "        if has_children and has_parent:\n",
    "            compare_histogram(hist_name + \" (e10s merged)\", \n",
    "                              addons_hist_data[\"e10s_merged\"],\n",
    "                              addons_hist_data[\"non_e10s\"],\n",
    "                              e10s_std[histogram].dropna(),\n",
    "                              non_e10s_std_hist,\n",
    "                              **kwargs)\n",
    "        \n",
    "        if has_parent:\n",
    "            compare_histogram(hist_name + \" (parent)\",\n",
    "                              addons_hist_data[\"e10s_parent\"],\n",
    "                              addons_hist_data[\"non_e10s\"],\n",
    "                              e10s_std[histogram + \"_parent\"].dropna(),\n",
    "                              non_e10s_std_hist,\n",
    "                              **kwargs)\n",
    "\n",
    "        if has_children:\n",
    "            compare_histogram(hist_name + \" (children)\",\n",
    "                              addons_hist_data[\"e10s_children\"],\n",
    "                              addons_hist_data[\"non_e10s\"],\n",
    "                              e10s_std[histogram + \"_children\"].dropna(),\n",
    "                              non_e10s_std_hist,\n",
    "                              **kwargs)\n",
    "\n",
    "def compare_scalars(metric, e10s_data, non_e10s_data, e10s_std=None, non_e10s_std=None, unit=\"units\"):\n",
    "    \"\"\" Prints info about the median difference between the groups, together with a p-value\n",
    "        for testing the difference.\n",
    "        \n",
    "        Optionally include a string indicating the units the metric is measured in.\n",
    "        If data is supplied, also print a comparison for non-addons cohorts.\n",
    "    \"\"\"\n",
    "    e10s_data = e10s_data.dropna()\n",
    "    non_e10s_data = non_e10s_data.dropna()\n",
    "    if len(e10s_data) == 0 or len(non_e10s_data) == 0:\n",
    "        print(\"Cannot run comparison: one of the groups has no non-missing observations.\")\n",
    "        return\n",
    "    \n",
    "    print(\"Comparison for {}{} (with add-ons):\\n\".format(metric, \" ({})\".format(unit) if unit != \"units\" else \"\"))\n",
    "    e10s_median = np.median(e10s_data)\n",
    "    non_e10s_median = np.median(non_e10s_data)\n",
    "    mdiff = median_diff(e10s_data, non_e10s_data)\n",
    "    print(\"- Median with e10s is {:.3g} {} {} median without e10s.\"\\\n",
    "         .format(\n",
    "            #abs(mdiff),\n",
    "            mdiff,\n",
    "            unit,\n",
    "            #\"higher than\" if mdiff >= 0 else \"lower than\"\n",
    "            \"different from\"))\n",
    "    print(\"- This is a relative difference of {:.1f}%.\".format(float(mdiff) / non_e10s_median * 100))\n",
    "    print(\"- E10s group median is {:.4g}, non-e10s group median is {:.4g}.\".format(e10s_median, non_e10s_median))\n",
    "            \n",
    "    print(\"\\nThe probability of this difference occurring purely by chance is {:.3f}.\"\\\n",
    "        .format(grouped_permutation_test(median_diff, [e10s_data, non_e10s_data], num_samples=10000)))\n",
    "    \n",
    "    if e10s_std is not None and non_e10s_std is not None:\n",
    "        ## Include a comparison between non-addon cohorts.\n",
    "        e10s_std = e10s_std.dropna()\n",
    "        non_e10s_std = non_e10s_std.dropna()\n",
    "        if len(e10s_std) > 0 and len(non_e10s_std) > 0:\n",
    "            non_e10s_std_median = np.median(non_e10s_std)\n",
    "            mdiff_std = median_diff(e10s_std, non_e10s_std)\n",
    "            print(\"\\nFor cohorts with no add-ons, median with e10s is {:.3g} {} ({:.1f}%) {} median without\"\\\n",
    "                 .format(\n",
    "                    #abs(mdiff_std),\n",
    "                    mdiff_std,\n",
    "                    unit,\n",
    "                    float(mdiff_std) / non_e10s_std_median * 100,\n",
    "                    #\"higher than\" if mdiff_std >= 0 else \"lower than\"\n",
    "                    \"different from\"))\n",
    "\n",
    "    \n",
    "def link_to_histogram(hist_name):\n",
    "    \"\"\" Create a link to the histogram definition in Markdown. \"\"\"\n",
    "    return \"[{}](https://dxr.mozilla.org/mozilla-central/search?q={}+file%3AHistograms.json&redirect=true)\"\\\n",
    "            .format(hist_name, hist_name)\n",
    "\n",
    "def hist_base_name(path_to_histogram):\n",
    "    \"\"\" Remove any path components from histogram name.\n",
    "    \n",
    "        If histogram is specified as a path in the payload, with separator '/',\n",
    "        remove everything but the last component (the actual name).\n",
    "    \"\"\"\n",
    "    return path_to_histogram.rsplit(\"/\")[-1]\n",
    "\n",
    "## Hack to render links in code output.\n",
    "from IPython.display import Markdown, display\n",
    "def print_with_markdown(md_text):\n",
    "    \"\"\" Print Markdown text so that it renders correctly in the cell output. \"\"\"\n",
    "    display(Markdown(md_text))\n",
    "\n",
    "def sample_size_str(sample_size, cohort_size=None):\n",
    "    \"\"\" Convert a sample size to a string representation, including a percentage if available. \"\"\"\n",
    "    if sample_size == 0:\n",
    "        return \"No\"\n",
    "    if cohort_size:\n",
    "        if sample_size == cohort_size:\n",
    "            return \"All\"\n",
    "        return \"{} ({:.1f}%)\".format(sample_size, float(sample_size) / cohort_size * 100)\n",
    "    return str(sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get e10s/non-e10s cohorts for the add-ons experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derived dataset is computed from profiles on Beta 49 who have e10sCohort set. It contains a single record (ping) per client, which is randomly selected from among the client's pings during the date range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- clientId: string (nullable = true)\n",
      " |-- e10sCohort: string (nullable = true)\n",
      " |-- creationTimestamp: string (nullable = true)\n",
      " |-- submissionDate: string (nullable = true)\n",
      " |-- documentId: string (nullable = true)\n",
      " |-- sampleId: integer (nullable = true)\n",
      " |-- buildId: string (nullable = true)\n",
      " |-- simpleMeasurements: string (nullable = true)\n",
      " |-- settings: string (nullable = true)\n",
      " |-- addons: string (nullable = true)\n",
      " |-- system: string (nullable = true)\n",
      " |-- build: string (nullable = true)\n",
      " |-- threadHangStats: string (nullable = true)\n",
      " |-- histograms: string (nullable = true)\n",
      " |-- keyedHistograms: string (nullable = true)\n",
      " |-- childPayloads: string (nullable = true)\n",
      " |-- processes: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = sqlContext.read.parquet(\n",
    "    \"s3://telemetry-parquet/e10s_experiment_view/e10s_addons_beta49_cohorts/v20160914_20160921/\")\n",
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many records are in the overall dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3549578"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the cohorts, and how many clients do we have in each cohort?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 14.8 s\n",
      "\n",
      "Total number of clients: 3,549,578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'addons-set2a-control', 14647, '0.41%'),\n",
       " (u'addons-set2a-test', 14934, '0.42%'),\n",
       " (u'addons-set49a-control', 30059, '0.85%'),\n",
       " (u'addons-set49a-test', 29771, '0.84%'),\n",
       " (u'control', 754447, '21.25%'),\n",
       " (u'disqualified', 25, '0.00%'),\n",
       " (u'disqualified-control', 975680, '27.49%'),\n",
       " (u'disqualified-test', 974619, '27.46%'),\n",
       " (u'optedIn', 3426, '0.10%'),\n",
       " (u'optedOut', 11620, '0.33%'),\n",
       " (u'test', 735774, '20.73%'),\n",
       " (u'unknown', 4458, '0.13%'),\n",
       " (u'unsupportedChannel', 118, '0.00%')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time cohort_counts = dataset.groupby(\"e10sCohort\").count().collect()\n",
    "dataset_count = sum(map(lambda r: r[\"count\"], cohort_counts))\n",
    "\n",
    "def cohort_proportions(r):\n",
    "    prop = r[\"count\"] * 100.0 / dataset_count\n",
    "    return (r[\"e10sCohort\"], r[\"count\"], \"{:.2f}%\".format(prop))\n",
    "\n",
    "print(\"\\nTotal number of clients: {:,}\".format(dataset_count))\n",
    "sorted(map(cohort_proportions, cohort_counts), key = lambda r: r[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restrict to pings belonging to the e10s add-ons experiment. Also include the standard e10s test/control for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We introduced new labels for the add-ons cohorts intended for Release 49. Group them together here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(e10sCohort=u'disqualified-test', count=974619),\n",
       " Row(e10sCohort=u'disqualified-control', count=975680),\n",
       " Row(e10sCohort=u'control', count=754447),\n",
       " Row(e10sCohort=u'addons-set2a-test', count=44705),\n",
       " Row(e10sCohort=u'addons-set2a-control', count=44706),\n",
       " Row(e10sCohort=u'test', count=735774)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_addons_groups = fun.when(dataset.e10sCohort == \"addons-set49a-control\", \"addons-set2a-control\")\\\n",
    "    .otherwise(fun.when(dataset.e10sCohort == \"addons-set49a-test\", \"addons-set2a-test\")\\\n",
    "        .otherwise(dataset.e10sCohort))\n",
    "dataset = dataset.withColumn(\"e10sCohort\", merged_addons_groups)\n",
    "\n",
    "dataset.filter(\"e10sCohort like '%control' or e10sCohort like '%test'\")\\\n",
    "    .groupby(\"e10sCohort\").count().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addons_exp_dataset = dataset.filter(\n",
    "        \"e10sCohort in ('addons-set2a-test', 'addons-set2a-control', 'test', 'control')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many clients are left?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1579632"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addons_exp_dataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make sure that the pings tagged into the two cohorts satisfy the basic assumptions of the experiment, as this not guaranteed. All pings should have active addons, and e10s should be enabled if and only if the ping belongs to the test cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def e10s_status_check(settings, addons):\n",
    "    \"\"\" Check whether e10s is enabled, and whether there are add-ons. \"\"\"\n",
    "    e10sEnabled = json.loads(settings).get(\"e10sEnabled\")\n",
    "    active_addons = json.loads(addons).get(\"activeAddons\")\n",
    "    return Row(\n",
    "        e10s_enabled = bool(e10sEnabled), \n",
    "        has_addons = bool(active_addons)\n",
    "    )\n",
    "\n",
    "def bad_ping(cohort, settings, addons):\n",
    "    \"\"\" e10s should be enabled iff the profile is in the test cohort, and profiles should have active add-ons\n",
    "        iff they are in the addons cohorts. \n",
    "    \"\"\"\n",
    "    check_data = e10s_status_check(settings, addons)\n",
    "    is_bad = cohort.endswith(\"test\") != check_data.e10s_enabled\n",
    "    if cohort.startswith(\"addons\"):\n",
    "        is_bad = is_bad or not check_data.has_addons\n",
    "    return is_bad\n",
    "\n",
    "## Add a Column to the DF with the outcome of the check.\n",
    "## This will be used to remove any bad rows after examining them.\n",
    "from pyspark.sql.types import BooleanType\n",
    "status_check_udf = fun.udf(bad_ping, BooleanType())\n",
    "addons_exp_dataset_check = addons_exp_dataset.withColumn(\"badPing\",\n",
    "    status_check_udf(addons_exp_dataset.e10sCohort, addons_exp_dataset.settings, addons_exp_dataset.addons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are any bad pings, describe the problems and remove them from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issues:\n",
      "(u'addons-set2a-test', Row(e10s_enabled=False, has_addons=True)): 10\n",
      "(u'addons-set2a-test', Row(e10s_enabled=True, has_addons=False)): 65\n",
      "(u'addons-set2a-test', Row(e10s_enabled=False, has_addons=False)): 1\n",
      "(u'addons-set2a-control', Row(e10s_enabled=False, has_addons=False)): 119\n"
     ]
    }
   ],
   "source": [
    "addons_exp_dataset_bad = addons_exp_dataset_check.filter(\"badPing\")\\\n",
    "    .select(\"e10sCohort\", \"settings\", \"addons\")\\\n",
    "    .rdd\n",
    "\n",
    "has_bad = not addons_exp_dataset_bad.isEmpty()\n",
    "if not has_bad:\n",
    "    print(\"No issues\")\n",
    "else:\n",
    "    check_counts = addons_exp_dataset_bad\\\n",
    "        .map(lambda r: (r.e10sCohort, e10s_status_check(r.settings, r.addons)))\\\n",
    "        .countByValue()\n",
    "    print(\"Issues:\")\n",
    "    for k, v in check_counts.iteritems():\n",
    "        print(\"{}: {}\".format(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing these pings from the dataset.\n",
      "The dataset now contains 1579437 clients\n"
     ]
    }
   ],
   "source": [
    "if has_bad:\n",
    "    print(\"\\nRemoving these pings from the dataset.\")\n",
    "    addons_exp_dataset = addons_exp_dataset_check.filter(\"not badPing\").drop(\"badPing\")\n",
    "    print(\"The dataset now contains {} clients\".format(addons_exp_dataset.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submissionDate</th>\n",
       "      <th>e10sCohort</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20160914</td>\n",
       "      <td>addons-set2a-control</td>\n",
       "      <td>5773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20160914</td>\n",
       "      <td>addons-set2a-test</td>\n",
       "      <td>5971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20160914</td>\n",
       "      <td>control</td>\n",
       "      <td>99436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20160914</td>\n",
       "      <td>test</td>\n",
       "      <td>96889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20160915</td>\n",
       "      <td>addons-set2a-control</td>\n",
       "      <td>5502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20160915</td>\n",
       "      <td>addons-set2a-test</td>\n",
       "      <td>5594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20160915</td>\n",
       "      <td>control</td>\n",
       "      <td>93311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20160915</td>\n",
       "      <td>test</td>\n",
       "      <td>91591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20160916</td>\n",
       "      <td>addons-set2a-control</td>\n",
       "      <td>5366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20160916</td>\n",
       "      <td>addons-set2a-test</td>\n",
       "      <td>5420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20160916</td>\n",
       "      <td>control</td>\n",
       "      <td>87888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20160916</td>\n",
       "      <td>test</td>\n",
       "      <td>86017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20160917</td>\n",
       "      <td>addons-set2a-control</td>\n",
       "      <td>4739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20160917</td>\n",
       "      <td>addons-set2a-test</td>\n",
       "      <td>4571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20160917</td>\n",
       "      <td>control</td>\n",
       "      <td>74323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20160917</td>\n",
       "      <td>test</td>\n",
       "      <td>72734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20160918</td>\n",
       "      <td>addons-set2a-control</td>\n",
       "      <td>4585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20160918</td>\n",
       "      <td>addons-set2a-test</td>\n",
       "      <td>4497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20160918</td>\n",
       "      <td>control</td>\n",
       "      <td>60747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20160918</td>\n",
       "      <td>test</td>\n",
       "      <td>58857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20160919</td>\n",
       "      <td>addons-set2a-control</td>\n",
       "      <td>5957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20160919</td>\n",
       "      <td>addons-set2a-test</td>\n",
       "      <td>6060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20160919</td>\n",
       "      <td>control</td>\n",
       "      <td>110090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20160919</td>\n",
       "      <td>test</td>\n",
       "      <td>107717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20160920</td>\n",
       "      <td>addons-set2a-control</td>\n",
       "      <td>6059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20160920</td>\n",
       "      <td>addons-set2a-test</td>\n",
       "      <td>6163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20160920</td>\n",
       "      <td>control</td>\n",
       "      <td>109972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20160920</td>\n",
       "      <td>test</td>\n",
       "      <td>107264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20160921</td>\n",
       "      <td>addons-set2a-control</td>\n",
       "      <td>6606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20160921</td>\n",
       "      <td>addons-set2a-test</td>\n",
       "      <td>6353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20160921</td>\n",
       "      <td>control</td>\n",
       "      <td>118680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20160921</td>\n",
       "      <td>test</td>\n",
       "      <td>114705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   submissionDate            e10sCohort   count\n",
       "0        20160914  addons-set2a-control    5773\n",
       "1        20160914     addons-set2a-test    5971\n",
       "2        20160914               control   99436\n",
       "3        20160914                  test   96889\n",
       "4        20160915  addons-set2a-control    5502\n",
       "5        20160915     addons-set2a-test    5594\n",
       "6        20160915               control   93311\n",
       "7        20160915                  test   91591\n",
       "8        20160916  addons-set2a-control    5366\n",
       "9        20160916     addons-set2a-test    5420\n",
       "10       20160916               control   87888\n",
       "11       20160916                  test   86017\n",
       "12       20160917  addons-set2a-control    4739\n",
       "13       20160917     addons-set2a-test    4571\n",
       "14       20160917               control   74323\n",
       "15       20160917                  test   72734\n",
       "16       20160918  addons-set2a-control    4585\n",
       "17       20160918     addons-set2a-test    4497\n",
       "18       20160918               control   60747\n",
       "19       20160918                  test   58857\n",
       "20       20160919  addons-set2a-control    5957\n",
       "21       20160919     addons-set2a-test    6060\n",
       "22       20160919               control  110090\n",
       "23       20160919                  test  107717\n",
       "24       20160920  addons-set2a-control    6059\n",
       "25       20160920     addons-set2a-test    6163\n",
       "26       20160920               control  109972\n",
       "27       20160920                  test  107264\n",
       "28       20160921  addons-set2a-control    6606\n",
       "29       20160921     addons-set2a-test    6353\n",
       "30       20160921               control  118680\n",
       "31       20160921                  test  114705"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addons_exp_dataset.groupBy(\"submissionDate\", \"e10sCohort\").count()\\\n",
    "    .sort(\"submissionDate\", \"e10sCohort\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 6 in stage 25.0 failed 4 times, most recent failure: Lost task 6.3 in stage 25.0 (TID 11848, ip-172-31-6-7.us-west-2.compute.internal): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Container marked as failed: container_1474666600867_0008_01_000043 on host: ip-172-31-6-7.us-west-2.compute.internal. Exit status: 52. Diagnostics: Exception from container-launch.\nContainer id: container_1474666600867_0008_01_000043\nExit code: 52\nStack trace: ExitCodeException exitCode=52: \n\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:545)\n\tat org.apache.hadoop.util.Shell.run(Shell.java:456)\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)\n\tat org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\nContainer exited with a non-zero exit code 52\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:358)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:892)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:211)\n\tat java.lang.Thread.run(Thread.java:745)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b0e8995cceb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maddons_exp_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"e10sCohort\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountByValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/lib/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcountByValue\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1212\u001b[0m                 \u001b[0mm1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mm1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1214\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcountPartition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmergeMaps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mreduce\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    800\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 802\u001b[1;33m         \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    803\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    774\u001b[0m         \"\"\"\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 776\u001b[1;33m             \u001b[0mport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    777\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hadoop/anaconda2/lib/python2.7/site-packages/py4j/java_gateway.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1133\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hadoop/anaconda2/lib/python2.7/site-packages/py4j/protocol.pyc\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    318\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 6 in stage 25.0 failed 4 times, most recent failure: Lost task 6.3 in stage 25.0 (TID 11848, ip-172-31-6-7.us-west-2.compute.internal): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Container marked as failed: container_1474666600867_0008_01_000043 on host: ip-172-31-6-7.us-west-2.compute.internal. Exit status: 52. Diagnostics: Exception from container-launch.\nContainer id: container_1474666600867_0008_01_000043\nExit code: 52\nStack trace: ExitCodeException exitCode=52: \n\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:545)\n\tat org.apache.hadoop.util.Shell.run(Shell.java:456)\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722)\n\tat org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\nContainer exited with a non-zero exit code 52\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:358)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:892)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:211)\n\tat java.lang.Thread.run(Thread.java:745)\n"
     ]
    }
   ],
   "source": [
    "addons_exp_dataset.rdd.map(lambda r: r[\"e10sCohort\"]).countByValue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Dataframe to RDD of pings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def row_2_ping(row):\n",
    "    ping = {\n",
    "        \"payload\": {\"simpleMeasurements\": json.loads(row.simpleMeasurements) if row.simpleMeasurements else {},\n",
    "                    \"histograms\": json.loads(row.histograms) if row.histograms else {},\n",
    "                    \"keyedHistograms\": json.loads(row.keyedHistograms) if row.keyedHistograms else {},\n",
    "                    \"childPayloads\": json.loads(row.childPayloads) if row.childPayloads else {},\n",
    "                    \"threadHangStats\": json.loads(row.threadHangStats)} if row.threadHangStats else {},\n",
    "       \"e10s\": True if row.e10sCohort.endswith(\"test\") else False,\n",
    "       \"addons\": True if row.e10sCohort.startswith(\"addons\") else False,\n",
    "       \"system\": json.loads(row.system),\n",
    "       \"cohort\": row.e10sCohort\n",
    "    }\n",
    "    return ping\n",
    "\n",
    "def notxp(p):\n",
    "    os = p.get(\"system\", {}).get(\"os\", {})\n",
    "    return os[\"name\"] != \"Windows_NT\" or os[\"version\"] != \"5.1\"\n",
    "\n",
    "subset = addons_exp_dataset.rdd.map(row_2_ping).filter(notxp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_gecko_activity(ping):\n",
    "    uptime = ping[\"payload\"].get(\"simpleMeasurements\", {}).get(\"totalTime\", -1) / 60\n",
    "    if uptime <= 0:\n",
    "        return ping\n",
    "\n",
    "    def get_hangs_per_minute(threads, thread_name, uptime):\n",
    "        for thread in threads:\n",
    "            if thread[\"name\"] == thread_name:\n",
    "                activity = thread[\"activity\"][\"values\"]\n",
    "                if activity:\n",
    "                    histogram = pd.Series(activity.values(), index=map(int, activity.keys())).sort_index()\n",
    "                    # 255 is upper bound for 128-255ms bucket.\n",
    "                    return histogram[histogram.index >= 255].sum() / uptime\n",
    "        return None\n",
    "\n",
    "    threads = ping[\"payload\"].get(\"threadHangStats\", {})\n",
    "    ping[\"parent_hangs_per_minute\"] = get_hangs_per_minute(threads, \"Gecko\", uptime)\n",
    "\n",
    "    child_payloads = ping[\"payload\"].get(\"childPayloads\", [])\n",
    "    child_hangs_per_minute = []\n",
    "    for payload in child_payloads:\n",
    "        child_uptime = payload.get(\"simpleMeasurements\", {}).get(\"totalTime\", -1) / 60\n",
    "        if child_uptime <= 0:\n",
    "            continue\n",
    "        child_threads = payload.get(\"threadHangStats\", {})\n",
    "        child_hangs = get_hangs_per_minute(child_threads, \"Gecko_Child\", child_uptime)\n",
    "        if child_hangs:\n",
    "            child_hangs_per_minute.append(child_hangs)\n",
    "\n",
    "    if len(child_hangs_per_minute) > 0:\n",
    "        ping[\"child_hangs_per_minute\"] = sum(child_hangs_per_minute) / len(child_hangs_per_minute)\n",
    "\n",
    "    return ping\n",
    "\n",
    "subset = subset.map(add_gecko_activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, how many clients are left in each cohort? Key first by cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset = subset.map(lambda r: (r[\"cohort\"], r))\n",
    "\n",
    "cohort_sizes = subset.countByKey()\n",
    "cohort_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We include the standard e10s cohorts to provide an additional comparison to the addon cohorts. If we see an e10s-related difference for profiles with add-ons, we want to see whether the difference is specific to having add-ons, or whether it occurs regardless.\n",
    "\n",
    "Since the addon cohorts are much smaller than the standard ones, we draw samples from the standard ones to make them approximately the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_prop_test = cohort_sizes[\"addons-set2a-test\"] / cohort_sizes[\"test\"]\n",
    "target_prop_control = cohort_sizes[\"addons-set2a-control\"] / cohort_sizes[\"control\"]\n",
    "sampling_props = {\n",
    "    \"addons-set2a-test\": 1.0,\n",
    "    \"addons-set2a-control\": 1.0,\n",
    "    \"test\": target_prop_test,\n",
    "    \"control\": target_prop_control    \n",
    "}\n",
    "subset = subset.sampleByKey(False, sampling_props)\\\n",
    "    .persist(StorageLevel.MEMORY_AND_DISK_SER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the final cohort sizes, and wrap them into the histogram comparison functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e10s_addon_cohort_sizes = subset.countByKey()\n",
    "\n",
    "## Remove the cohort label key from the dataset.\n",
    "subset = subset.map(lambda r: r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Final cohort sizes:\")\n",
    "print(\" - e10s (with add-ons): {}\".format(e10s_addon_cohort_sizes[\"addons-set2a-test\"]))\n",
    "print(\" - non-e10s (with add-ons): {}\".format(e10s_addon_cohort_sizes[\"addons-set2a-control\"]))\n",
    "print(\" - e10s (no add-ons): {}\".format(e10s_addon_cohort_sizes[\"test\"]))\n",
    "print(\" - non-e10s (no add-ons): {}\".format(e10s_addon_cohort_sizes[\"control\"]))\n",
    "\n",
    "def compare_histograms(pings, *histogram_names, **kwargs):\n",
    "    return compare_e10s_histograms(pings, e10s_addon_cohort_sizes, *histogram_names, **kwargs)\n",
    "    \n",
    "def compare_count_histograms(pings, *histogram_names, **kwargs):\n",
    "    return compare_e10s_count_histograms(pings, e10s_addon_cohort_sizes, *histogram_names, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Jank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset,  \n",
    "                   \"payload/histograms/GC_MAX_PAUSE_MS\",\n",
    "                   \"payload/histograms/CYCLE_COLLECTOR_MAX_PAUSE\",\n",
    "                   \"payload/histograms/INPUT_EVENT_RESPONSE_MS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Page load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset, \"payload/histograms/FX_PAGE_LOAD_MS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Startup/shutdown time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple = pd.DataFrame(get_pings_properties(subset, [\n",
    "    \"payload/simpleMeasurements/firstPaint\",\n",
    "    \"payload/simpleMeasurements/sessionRestored\",\n",
    "    \"payload/simpleMeasurements/shutdownDuration\",\n",
    "    \"e10s\",\n",
    "    \"addons\"]).collect())\n",
    "\n",
    "eSimple = simple[simple[\"addons\"] & simple[\"e10s\"]]\n",
    "nSimple = simple[simple[\"addons\"] & ~simple[\"e10s\"]]\n",
    "eSimple_std = simple[~simple[\"addons\"] & simple[\"e10s\"]]\n",
    "nSimple_std = simple[~simple[\"addons\"] & ~simple[\"e10s\"]]\n",
    "\n",
    "len(eSimple), len(nSimple), len(eSimple_std), len(nSimple_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_scalars(\"firstPaint time\",\n",
    "                eSimple[\"payload/simpleMeasurements/firstPaint\"],\n",
    "                nSimple[\"payload/simpleMeasurements/firstPaint\"],\n",
    "                eSimple_std[\"payload/simpleMeasurements/firstPaint\"],\n",
    "                nSimple_std[\"payload/simpleMeasurements/firstPaint\"],\n",
    "                \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_scalars(\"sessionRestored time\",\n",
    "                eSimple[\"payload/simpleMeasurements/sessionRestored\"],\n",
    "                nSimple[\"payload/simpleMeasurements/sessionRestored\"],\n",
    "                eSimple_std[\"payload/simpleMeasurements/sessionRestored\"],\n",
    "                nSimple_std[\"payload/simpleMeasurements/sessionRestored\"],\n",
    "               \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_scalars(\"shutdownDuration time\",\n",
    "                eSimple[\"payload/simpleMeasurements/shutdownDuration\"],\n",
    "                nSimple[\"payload/simpleMeasurements/shutdownDuration\"],\n",
    "                eSimple_std[\"payload/simpleMeasurements/shutdownDuration\"],\n",
    "                nSimple_std[\"payload/simpleMeasurements/shutdownDuration\"],\n",
    "               \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Scrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset, \"payload/histograms/FX_REFRESH_DRIVER_SYNC_SCROLL_FRAME_DELAY_MS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Plugin jank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broken for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compare_histograms(subset,\n",
    "#                   \"payload/keyedHistograms/BLOCKED_ON_PLUGIN_MODULE_INIT_MS\",\n",
    "#                   \"payload/keyedHistograms/BLOCKED_ON_PLUGIN_INSTANCE_INIT_MS\",\n",
    "#                   \"payload/keyedHistograms/BLOCKED_ON_PLUGIN_INSTANCE_DESTROY_MS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset,\n",
    "                   \"payload/histograms/MEMORY_TOTAL\",\n",
    "                   \"payload/histograms/MEMORY_VSIZE_MAX_CONTIGUOUS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 UI Smoothness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: `FX_TAB_SWITCH_TOTAL_MS` was renamed to `FX_TAB_SWITCH_TOTAL_E10S_MS` for e10s profiles, so this comparison is currently broken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset, \"payload/histograms/FX_TAB_SWITCH_TOTAL_MS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11 Slow Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_count_histograms(subset, \"payload/histograms/SLOW_SCRIPT_PAGE_COUNT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generic stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple = pd.DataFrame(get_pings_properties(subset, [\n",
    "    \"payload/simpleMeasurements/firstPaint\",\n",
    "    \"payload/simpleMeasurements/firstLoadURI\",\n",
    "    \"payload/simpleMeasurements/sessionRestored\",\n",
    "    \"payload/simpleMeasurements/sessionRestoreInit\",\n",
    "    \"payload/simpleMeasurements/shutdownDuration\",\n",
    "    \"e10s\",\n",
    "    \"parent_hangs_per_minute\",\n",
    "    \"child_hangs_per_minute\"]).collect())\n",
    "\n",
    "eSimple = simple[simple[\"e10s\"] == True]\n",
    "nSimple = simple[simple[\"e10s\"] == False]\n",
    "len(eSimple), len(nSimple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Startup time evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_scalars(\"startup time\", eSimple[\"payload/simpleMeasurements/firstPaint\"].dropna(), nSimple[\"payload/simpleMeasurements/firstPaint\"].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_scalars(\"startup time\", eSimple[\"payload/simpleMeasurements/firstLoadURI\"].dropna(), nSimple[\"payload/simpleMeasurements/firstLoadURI\"].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Shutdown time evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_scalars(\"shutdown duration\", eSimple[\"payload/simpleMeasurements/shutdownDuration\"].dropna(), nSimple[\"payload/simpleMeasurements/shutdownDuration\"].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Animation smoothness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset,\n",
    "                   \"payload/histograms/FX_TAB_ANIM_ANY_FRAME_INTERVAL_MS\",\n",
    "                   \"payload/histograms/FX_TAB_ANIM_OPEN_FRAME_INTERVAL_MS\",\n",
    "                   \"payload/histograms/FX_TAB_ANIM_OPEN_PREVIEW_FRAME_INTERVAL_MS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Graphics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset, \"payload/histograms/REFRESH_DRIVER_TICK\",\n",
    "                           \"payload/histograms/FX_REFRESH_DRIVER_CHROME_FRAME_DELAY_MS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Responsivness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Event processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset, \"payload/histograms/EVENTLOOP_UI_ACTIVITY_EXP_MS\",\n",
    "                           \"payload/histograms/INPUT_EVENT_RESPONSE_MS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_scalars(\"hangs over 100ms per minute (parent)\",\n",
    "                eSimple[\"parent_hangs_per_minute\"].dropna(),\n",
    "                nSimple[\"parent_hangs_per_minute\"].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_scalars(\"hangs over 100ms per minute (parent + child)\",\n",
    "                (eSimple[\"child_hangs_per_minute\"] + eSimple[\"parent_hangs_per_minute\"]).dropna(),\n",
    "                nSimple[\"parent_hangs_per_minute\"].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_count_histograms(subset, \"payload/keyedHistograms/SUBPROCESS_ABNORMAL_ABORT/plugin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Page load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset, \"payload/histograms/FX_PAGE_LOAD_MS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Slow scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_count_histograms(subset, \"payload/histograms/SLOW_SCRIPT_NOTICE_COUNT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_count_histograms(subset, \"payload/histograms/SLOW_SCRIPT_PAGE_COUNT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Window open time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset, \"payload/histograms/FX_NEW_WINDOW_MS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) Garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset, \n",
    "                   \"payload/histograms/GC_MS\", \n",
    "                   \"payload/histograms/GC_MAX_PAUSE_MS\", \n",
    "                   \"payload/histograms/GC_MARK_MS\", \n",
    "                   \"payload/histograms/GC_SWEEP_MS\", \n",
    "                   \"payload/histograms/GC_MARK_ROOTS_MS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset,\n",
    "                   \"payload/histograms/GC_MMU_50\",\n",
    "                   \"payload/histograms/GC_MARK_GRAY_MS\",\n",
    "                   \"payload/histograms/GC_SLICE_MS\",\n",
    "                   \"payload/histograms/GC_SCC_SWEEP_TOTAL_MS\",\n",
    "                   \"payload/histograms/GC_SCC_SWEEP_MAX_PAUSE_MS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g) Cycle Collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset,\n",
    "                   \"payload/histograms/CYCLE_COLLECTOR\",\n",
    "                   \"payload/histograms/CYCLE_COLLECTOR_WORKER\",\n",
    "                   \"payload/histograms/CYCLE_COLLECTOR_FULL\",\n",
    "                   \"payload/histograms/CYCLE_COLLECTOR_MAX_PAUSE\",\n",
    "                   \"payload/histograms/CYCLE_COLLECTOR_TIME_BETWEEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Usage (bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset,\n",
    "                #   \"payload/histograms/MEMORY_TOTAL\",\n",
    "                 #  \"payload/histograms/MEMORY_VSIZE\",\n",
    "                  # \"payload/histograms/MEMORY_VSIZE_MAX_CONTIGUOUS\",\n",
    "                  # \"payload/histograms/MEMORY_HEAP_ALLOCATED\",\n",
    "                   \"payload/histograms/MEMORY_JS_GC_HEAP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset,\n",
    "                   \"payload/histograms/MEMORY_IMAGES_CONTENT_USED_UNCOMPRESSED\",\n",
    "                   \"payload/histograms/MEMORY_STORAGE_SQLITE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) JS compartments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset,\n",
    "                   \"payload/histograms/MEMORY_JS_COMPARTMENTS_SYSTEM\",\n",
    "                   \"payload/histograms/MEMORY_JS_COMPARTMENTS_USER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Low memory events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset,\n",
    "                   \"payload/histograms/LOW_MEMORY_EVENTS_VIRTUAL\",\n",
    "                   \"payload/histograms/LOW_MEMORY_EVENTS_PHYSICAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Page faults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset,\n",
    "                   \"payload/histograms/PAGE_FAULTS_HARD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) Ghost windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset,\n",
    "                   \"payload/histograms/GHOST_WINDOWS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differences discovered by comparing all histograms (see Bug [1198638](https://bugzilla.mozilla.org/show_bug.cgi?id=1198638))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset,\n",
    "                   \"payload/histograms/STARTUP_HTTP_CACHE_DISPOSITION_2_V2\",\n",
    "                   \"payload/histograms/STARTUP_NETWORK_CACHE_METADATA_FIRST_READ_TIME_MS\",\n",
    "                   \"payload/histograms/STARTUP_NETWORK_CACHE_V2_HIT_TIME_MS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset,\n",
    "                   \"payload/histograms/HTTP_PAGE_OPEN_TO_FIRST_FROM_CACHE_V2\",\n",
    "                   \"payload/histograms/HTTP_PAGE_COMPLETE_LOAD_CACHED_V2\",\n",
    "                   \"payload/histograms/HTTP_PAGE_COMPLETE_LOAD\",\n",
    "                   \"payload/histograms/HTTP_SUB_COMPLETE_LOAD_CACHED_V2\",\n",
    "                   \"payload/histograms/HTTP_SUB_COMPLETE_LOAD\",                   \n",
    "                   \"payload/histograms/HTTP_SUB_REVALIDATION\",\n",
    "                   \"payload/histograms/HTTP_SUB_OPEN_TO_FIRST_FROM_CACHE_V2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset, \n",
    "                   \"payload/histograms/FX_THUMBNAILS_CAPTURE_TIME_MS\",                   \n",
    "                   \"payload/histograms/LOCALDOMSTORAGE_GETVALUE_BLOCKING_MS\",\n",
    "                   \"payload/histograms/FX_SESSION_RESTORE_RESTORE_WINDOW_MS\",\n",
    "                   \"payload/histograms/FX_SESSION_RESTORE_STARTUP_ONLOAD_INITIAL_WINDOW_MS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset, \n",
    "                   \"payload/histograms/IMAGE_DECODE_ON_DRAW_LATENCY\",\n",
    "                   \"payload/histograms/IMAGE_DECODE_SPEED_GIF\",\n",
    "                   \"payload/histograms/AUDIOSTREAM_LATER_OPEN_MS\",\n",
    "                   \"payload/histograms/AUDIOSTREAM_FIRST_OPEN_MS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset, \n",
    "                   \"payload/histograms/MEMORY_STORAGE_SQLITE\",\n",
    "                   \"payload/histograms/BLOCKED_ON_PLUGIN_INSTANCE_INIT_MS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IPython.core.pylabtools.figsize(32, 7)\n",
    "compare_histograms(subset, \n",
    "                   \"payload/histograms/CERT_VALIDATION_HTTP_REQUEST_CANCELED_TIME\",\n",
    "                   \"payload/histograms/STARTUP_NETWORK_CACHE_METADATA_SIZE\",\n",
    "                   \"payload/histograms/STARTUP_NETWORK_CACHE_METADATA_FIRST_READ_SIZE\")\n",
    "IPython.core.pylabtools.figsize(16, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**bug 1226564** - please compare `HTTP_*_COMPLETE_LOAD_NET_V2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset,\n",
    "                   \"payload/histograms/HTTP_PAGE_COMPLETE_LOAD_NET_V2\",\n",
    "                   \"payload/histograms/HTTP_SUB_COMPLETE_LOAD_NET_V2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**bug 1255159** - Please look at FX_REFRESH_DRIVER_SYNC_SCROLL_FRAME_DELAY_MS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset, \"payload/histograms/FX_REFRESH_DRIVER_SYNC_SCROLL_FRAME_DELAY_MS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**bug 1273847** - Please look at SLOW_SCRIPT_NOTIFY_DELAY, SHUTDOWN_OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset, \"payload/histograms/SLOW_SCRIPT_NOTIFY_DELAY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_histograms(subset, \"payload/histograms/SHUTDOWN_OK\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
